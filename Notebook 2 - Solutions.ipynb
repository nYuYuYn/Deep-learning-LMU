{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a71def",
   "metadata": {},
   "source": [
    "#  Manually-constructed neural network for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6c6174",
   "metadata": {},
   "source": [
    "In the notebook of tutorial 1 (Notebook 1), we explored simple linear regression based on Portugese white wine data set. Here, we continue with the analysis of the same data set. However, we now manually implement a simple network for solving the regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13588b30",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69527811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set the path to the data\n",
    "csv_path = r\"C:\\Users\\Kepesidis\\Desktop\\Deep Learning for Physicists\\tutorials\\Tutorial 1\\winequality-white.csv\"\n",
    "data = pd.read_csv(csv_path, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84e31e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4898, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "762f377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "\n",
    "data_np = data.values # transform to numpy array\n",
    "\n",
    "np.random.shuffle(data_np) # randomly shaffle data\n",
    "\n",
    "# use first 3000 examples for training\n",
    "X_train = data_np[:3000,:11] # predictors\n",
    "y_train = data_np[:3000,11]  # target variable\n",
    "\n",
    "# and remaining examples for testing\n",
    "X_test = data_np[3000:,:11] # predictors\n",
    "y_test = data_np[3000:,11] # target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7dca1c",
   "metadata": {},
   "source": [
    "The main objective here is to train a neural network with one input layer, one hidden layer, and one output layer using gradient descent. First define the matrices and initialise with random values. We need W, b, W' and b'. The shapes will be:\n",
    "\n",
    "- W: (number of hidden nodes, number of inputs) named **W**\n",
    "- b: (number of hidden nodes) named **b**\n",
    "- W': (number of hidden nodes) named **Wp**\n",
    "- b': (one) named bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a7a9e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 11)\n"
     ]
    }
   ],
   "source": [
    "# Initialise weights with suitable random distributions\n",
    "\n",
    "hidden_nodes = 50 # number of nodes in the hidden layer\n",
    "n_inputs = 11 # input features in the dataset\n",
    "\n",
    "\n",
    "W = np.random.randn(hidden_nodes,11)*np.sqrt(2./n_inputs)\n",
    "b = np.random.randn(hidden_nodes)*np.sqrt(2./n_inputs)\n",
    "Wp = np.random.randn(hidden_nodes)*np.sqrt(2./hidden_nodes)\n",
    "bp = np.random.randn((1))\n",
    "\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ced5bcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb26169a",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c8ec66",
   "metadata": {},
   "source": [
    "1. Implement a forward pass of the network within the function **dnn()**. We want a network with one hidden layer. As activiation in the hidden layer $\\sigma$ we apply element-wise ReLu, while no activation is used for the output layer. The forward pass of the network then reads: \n",
    "$\\hat{y}=\\mathbf{W}^{\\prime} \\sigma(\\mathbf{W} \\vec{x}+\\vec{b})+b^{\\prime}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "632b405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use this implementation of the ReLu activation function\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5a6830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn(x,W,b,Wp,bp):\n",
    "\n",
    "    return np.dot(Wp, relu(np.dot(W,x) + b)) + bp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c65d8e6",
   "metadata": {},
   "source": [
    "2. Implement a function that uses one data point to update the weights using gradient descent. For the regression problem the objective function is the mean squared error between the prediction and the true label $y$: $ L=(\\hat{y}-y)^{2}$. Taking the partial derivatives - and diligently applying the chain rule - with respect to the different objects yields:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial L}{\\partial b^{\\prime}} &=2(\\hat{y}-y) \\\\\n",
    "\\frac{\\partial L}{\\partial b_{k}} &=2(\\hat{y}-y) \\mathbf{W}_{k}^{\\prime} \\theta\\left(\\sum_{i} \\mathbf{W}_{i k} x_{i}+b_{k}\\right) \\\\\n",
    "\\frac{\\partial L}{\\partial \\mathbf{W}_{k}^{\\prime}} &=2(\\hat{y}-y) \\sigma\\left(\\sum_{i} \\mathbf{W}_{i k} x_{i}+b_{k}\\right) \\\\\n",
    "\\frac{\\partial L}{\\partial \\mathbf{W}_{k m}} &=2(\\hat{y}-y) \\mathbf{W}_{m}^{\\prime} \\theta\\left(\\sum_{i} \\mathbf{W}_{i k} x_{i}+b_{m}\\right) x_{k}\n",
    "\\end{aligned}\n",
    "$$\n",
    "Here, $\\Theta$ denotes the Heaviside step function. Your task is to follow and complete the **update_weights()** function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec3c41f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(x,y, W, b, Wp, bp):\n",
    "    \n",
    "    lr = 0.00005\n",
    "\n",
    "    # SOLUTION\n",
    "\n",
    "    # Calculate the network output\n",
    "    phi = dnn(x,W,b,Wp,bp)\n",
    "\n",
    "    # Use the formulas derived to calculate the gradient for each of W,b,Wp,bp\n",
    "    delta_bp = 2 * (phi - y)\n",
    "    delta_Wp = 2 * (phi - y) * relu(np.dot(W,x) + b)\n",
    "    delta_b  = 2 * (phi - y) * Wp * np.heaviside(np.dot(W,x) + b, 0.5)\n",
    "    delta_W  = 2 * (phi - y) * np.outer(Wp * np.heaviside(np.dot(W,x) + b, 0.5), x)\n",
    "                \n",
    "    # Update the weights/bias following the rule:  X_new = X_old - learning_rate * gradient    \n",
    "    bp -= lr * delta_bp\n",
    "    Wp -= lr * delta_Wp\n",
    "    b  -= lr * delta_b\n",
    "    W  -= lr * delta_W\n",
    "    \n",
    "    return -1 # no return value needed, you can modify the weights in-place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf61f79a",
   "metadata": {},
   "source": [
    "## Training loop and evaluation below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ebe1b58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 2.1657583692550992 Test Loss: 2.336574297570434\n",
      "Epoch: 1 Train Loss: 0.8473933999985357 Test Loss: 0.9954634543949445\n",
      "Epoch: 2 Train Loss: 0.7033832298129076 Test Loss: 0.7729930634059105\n",
      "Epoch: 3 Train Loss: 0.6757907183681471 Test Loss: 0.735808179931544\n",
      "Epoch: 4 Train Loss: 0.6659944901238635 Test Loss: 0.7160145792131007\n",
      "Epoch: 5 Train Loss: 0.6558160288498905 Test Loss: 0.7122621663178694\n",
      "Epoch: 6 Train Loss: 0.6504766014995229 Test Loss: 0.7046082469539193\n",
      "Epoch: 7 Train Loss: 0.6460651138626461 Test Loss: 0.6975099921512085\n",
      "Epoch: 8 Train Loss: 0.6427504987550661 Test Loss: 0.6867880469144063\n",
      "Epoch: 9 Train Loss: 0.6389965683324892 Test Loss: 0.6832777349961735\n",
      "Epoch: 10 Train Loss: 0.6361713549288501 Test Loss: 0.6742720363840672\n",
      "Epoch: 11 Train Loss: 0.6325031633774052 Test Loss: 0.672211433733176\n",
      "Epoch: 12 Train Loss: 0.6287869069900565 Test Loss: 0.665112588495503\n",
      "Epoch: 13 Train Loss: 0.6254195708545602 Test Loss: 0.6636757470846254\n",
      "Epoch: 14 Train Loss: 0.622978064402875 Test Loss: 0.6573595627689943\n",
      "Epoch: 15 Train Loss: 0.6217256346974016 Test Loss: 0.6536338856179101\n",
      "Epoch: 16 Train Loss: 0.6207406931408859 Test Loss: 0.6561232611494212\n",
      "Epoch: 17 Train Loss: 0.6200225104345946 Test Loss: 0.6525592407536226\n",
      "Epoch: 18 Train Loss: 0.6192807713026597 Test Loss: 0.6492559490080851\n",
      "Epoch: 19 Train Loss: 0.6186106502882528 Test Loss: 0.6467477845302725\n",
      "Epoch: 20 Train Loss: 0.6180731291451923 Test Loss: 0.6455282418736149\n",
      "Epoch: 21 Train Loss: 0.6173253091009694 Test Loss: 0.6480669783725829\n",
      "Epoch: 22 Train Loss: 0.6166845366716562 Test Loss: 0.6452235302771675\n",
      "Epoch: 23 Train Loss: 0.6161883284501188 Test Loss: 0.6431888416457947\n",
      "Epoch: 24 Train Loss: 0.6156791676499997 Test Loss: 0.6413556504829465\n",
      "Epoch: 25 Train Loss: 0.6152054358883394 Test Loss: 0.6401123369270917\n",
      "Epoch: 26 Train Loss: 0.6146847609206906 Test Loss: 0.6387078450867758\n",
      "Epoch: 27 Train Loss: 0.6142798555391025 Test Loss: 0.6378416562548754\n",
      "Epoch: 28 Train Loss: 0.6138531975107014 Test Loss: 0.636733576388015\n",
      "Epoch: 29 Train Loss: 0.6132324242618211 Test Loss: 0.6355535790710789\n",
      "Epoch: 30 Train Loss: 0.6129641672750116 Test Loss: 0.6348301612510879\n",
      "Epoch: 31 Train Loss: 0.6124188539195291 Test Loss: 0.6337332355631351\n",
      "Epoch: 32 Train Loss: 0.6121925838549882 Test Loss: 0.6330386256440493\n",
      "Epoch: 33 Train Loss: 0.6119873928381793 Test Loss: 0.6325873241627108\n",
      "Epoch: 34 Train Loss: 0.6116207713149783 Test Loss: 0.631844200507597\n",
      "Epoch: 35 Train Loss: 0.6111956245691742 Test Loss: 0.6309557858135407\n",
      "Epoch: 36 Train Loss: 0.6109235171712641 Test Loss: 0.6303793866951507\n",
      "Epoch: 37 Train Loss: 0.6106117058295495 Test Loss: 0.6297339858343254\n",
      "Epoch: 38 Train Loss: 0.610335247503813 Test Loss: 0.6291981402795739\n",
      "Epoch: 39 Train Loss: 0.6101628767711904 Test Loss: 0.628890751456155\n",
      "Epoch: 40 Train Loss: 0.6097729044834579 Test Loss: 0.6281314811902956\n",
      "Epoch: 41 Train Loss: 0.6094355245742267 Test Loss: 0.6274687986586278\n",
      "Epoch: 42 Train Loss: 0.6092099745319068 Test Loss: 0.6271510244091599\n",
      "Epoch: 43 Train Loss: 0.608919501469644 Test Loss: 0.6265775786426091\n",
      "Epoch: 44 Train Loss: 0.6086455674350495 Test Loss: 0.6261083639910121\n",
      "Epoch: 45 Train Loss: 0.6083026108565138 Test Loss: 0.6255357660537563\n",
      "Epoch: 46 Train Loss: 0.6090613529979101 Test Loss: 0.62675040389036\n",
      "Epoch: 47 Train Loss: 0.6087622244709678 Test Loss: 0.6262668920158937\n",
      "Epoch: 48 Train Loss: 0.6082942858895938 Test Loss: 0.6254329476870205\n",
      "Epoch: 49 Train Loss: 0.6082024529122679 Test Loss: 0.6254340671656442\n",
      "Epoch: 50 Train Loss: 0.6077450348075034 Test Loss: 0.6245859652723106\n",
      "Epoch: 51 Train Loss: 0.6074469647060803 Test Loss: 0.6241428197145824\n",
      "Epoch: 52 Train Loss: 0.6071797484174996 Test Loss: 0.6237518058093378\n",
      "Epoch: 53 Train Loss: 0.6068297765651595 Test Loss: 0.6231773887195065\n",
      "Epoch: 54 Train Loss: 0.6065792475473362 Test Loss: 0.6228429980670028\n",
      "Epoch: 55 Train Loss: 0.6062461372291936 Test Loss: 0.6223421411758948\n",
      "Epoch: 56 Train Loss: 0.6060539323506883 Test Loss: 0.6221024843630307\n",
      "Epoch: 57 Train Loss: 0.6057232108248475 Test Loss: 0.6216198396796475\n",
      "Epoch: 58 Train Loss: 0.605466679454296 Test Loss: 0.6212594765323061\n",
      "Epoch: 59 Train Loss: 0.6052686310976425 Test Loss: 0.6210151796880212\n",
      "Epoch: 60 Train Loss: 0.6050389050843905 Test Loss: 0.620692767460072\n",
      "Epoch: 61 Train Loss: 0.6047955333530751 Test Loss: 0.6205579091899641\n",
      "Epoch: 62 Train Loss: 0.6045548932441839 Test Loss: 0.6203824288001243\n",
      "Epoch: 63 Train Loss: 0.6043090346600378 Test Loss: 0.6201672285205437\n",
      "Epoch: 64 Train Loss: 0.6039461151345905 Test Loss: 0.6196927543903626\n",
      "Epoch: 65 Train Loss: 0.6039004802031946 Test Loss: 0.6197893371561815\n",
      "Epoch: 66 Train Loss: 0.6036630049345779 Test Loss: 0.6195640318934384\n",
      "Epoch: 67 Train Loss: 0.6032895243643246 Test Loss: 0.6190568068727894\n",
      "Epoch: 68 Train Loss: 0.6032205120582949 Test Loss: 0.6191136116923384\n",
      "Epoch: 69 Train Loss: 0.6031004435762611 Test Loss: 0.6191819280737022\n",
      "Epoch: 70 Train Loss: 0.6028838245171452 Test Loss: 0.6189375388206019\n",
      "Epoch: 71 Train Loss: 0.6023402286686967 Test Loss: 0.6179810965344993\n",
      "Epoch: 72 Train Loss: 0.6024898194763232 Test Loss: 0.6186903097103943\n",
      "Epoch: 73 Train Loss: 0.6024056787230617 Test Loss: 0.6187396645559433\n",
      "Epoch: 74 Train Loss: 0.6018645988285567 Test Loss: 0.6178624894838651\n",
      "Epoch: 75 Train Loss: 0.601812478021993 Test Loss: 0.617889289023434\n",
      "Epoch: 76 Train Loss: 0.6024072704506221 Test Loss: 0.618660745637429\n",
      "Epoch: 77 Train Loss: 0.6021638519267672 Test Loss: 0.6183515077929529\n",
      "Epoch: 78 Train Loss: 0.6019538695496822 Test Loss: 0.618051650603106\n",
      "Epoch: 79 Train Loss: 0.6017275564421678 Test Loss: 0.6178395245140802\n",
      "Epoch: 80 Train Loss: 0.6015383115170283 Test Loss: 0.6175951171840268\n",
      "Epoch: 81 Train Loss: 0.6008054258430812 Test Loss: 0.6166683497790936\n",
      "Epoch: 82 Train Loss: 0.6010909587792469 Test Loss: 0.6170667014162412\n",
      "Epoch: 83 Train Loss: 0.6008919005299952 Test Loss: 0.6168266465322922\n",
      "Epoch: 84 Train Loss: 0.6008884844233244 Test Loss: 0.6171573744072977\n",
      "Epoch: 85 Train Loss: 0.6005985387260274 Test Loss: 0.6169406417708116\n",
      "Epoch: 86 Train Loss: 0.6003652015321042 Test Loss: 0.616733684980719\n",
      "Epoch: 87 Train Loss: 0.6000615908987214 Test Loss: 0.6164220786779162\n",
      "Epoch: 88 Train Loss: 0.599837108797789 Test Loss: 0.616183372784755\n",
      "Epoch: 89 Train Loss: 0.5996325590513496 Test Loss: 0.6158914108170648\n",
      "Epoch: 90 Train Loss: 0.5993686084226768 Test Loss: 0.6155680066512634\n",
      "Epoch: 91 Train Loss: 0.5991864394433483 Test Loss: 0.6152502658076479\n",
      "Epoch: 92 Train Loss: 0.5989339899772514 Test Loss: 0.6150785414885686\n",
      "Epoch: 93 Train Loss: 0.5988835687647164 Test Loss: 0.6150526102625513\n",
      "Epoch: 94 Train Loss: 0.5986590937525165 Test Loss: 0.6148656347543572\n",
      "Epoch: 95 Train Loss: 0.598722510386659 Test Loss: 0.6163938296749099\n",
      "Epoch: 96 Train Loss: 0.598364022759006 Test Loss: 0.6160310048897175\n",
      "Epoch: 97 Train Loss: 0.5976145093499364 Test Loss: 0.6152944368794934\n",
      "Epoch: 98 Train Loss: 0.5975050582575258 Test Loss: 0.6150688795777053\n",
      "Epoch: 99 Train Loss: 0.5968673347237007 Test Loss: 0.6142757580032986\n",
      "Best loss: 0.6142757580032986 Final loss: 0.6142757580032986\n",
      "Correlation coefficient: 0.4783028688355225\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The code below implements the training.\n",
    "# If you correctly implement  dnn and update_weights above, \n",
    "# you should not need to change anything below. \n",
    "# (apart from increasing the number of epochs)\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# How many epochs to train\n",
    "n_epochs = 100\n",
    "\n",
    "# Loop over the epochs\n",
    "for ep in range(n_epochs):\n",
    "        \n",
    "    # Each epoch is a complete over the training data\n",
    "    for i in range(X_train.shape[0]):\n",
    "        \n",
    "        # pick one example\n",
    "        x = X_train[i]\n",
    "        y = y_train[i]\n",
    "\n",
    "        # use it to update the weights\n",
    "        update_weights(x,y,W,b,Wp,bp)\n",
    "    \n",
    "    # Calculate predictions for the full training and testing sample\n",
    "    y_pred_train = [dnn(x,W,b,Wp,bp)[0] for x in X_train]\n",
    "    y_pred = [dnn(x,W,b,Wp,bp)[0] for x in X_test]\n",
    "\n",
    "    # Calculate aver loss / example over the epoch\n",
    "    train_loss = sum((y_pred_train-y_train)**2) / y_train.shape[0]\n",
    "    test_loss = sum((y_pred-y_test)**2) / y_test.shape[0] \n",
    "    \n",
    "    # print some information\n",
    "    print(\"Epoch:\",ep, \"Train Loss:\", train_loss, \"Test Loss:\", test_loss)\n",
    "    \n",
    "    # and store the losses for later use\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    \n",
    "# After the training:\n",
    "    \n",
    "# Prepare scatter plot\n",
    "y_pred = [dnn(x,W,b,Wp,bp)[0] for x in X_test]\n",
    "\n",
    "print(\"Best loss:\", min(test_losses), \"Final loss:\", test_losses[-1])\n",
    "\n",
    "print(\"Correlation coefficient:\", np.corrcoef(y_pred,y_test)[0,1])\n",
    "plt.scatter(y_pred_train,y_train)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Prepare and loss over time\n",
    "plt.plot(train_losses,label=\"train\")\n",
    "plt.plot(test_losses,label=\"test\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125a8d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62189464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
